{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:17:03.983471Z","iopub.execute_input":"2025-01-10T19:17:03.983765Z","iopub.status.idle":"2025-01-10T19:17:08.244237Z","shell.execute_reply.started":"2025-01-10T19:17:03.983734Z","shell.execute_reply":"2025-01-10T19:17:08.243239Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:17:08.245403Z","iopub.execute_input":"2025-01-10T19:17:08.245663Z","iopub.status.idle":"2025-01-10T19:17:11.368294Z","shell.execute_reply.started":"2025-01-10T19:17:08.245637Z","shell.execute_reply":"2025-01-10T19:17:11.367306Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip show torch\n!pip show torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:17:11.370164Z","iopub.execute_input":"2025-01-10T19:17:11.370492Z","iopub.status.idle":"2025-01-10T19:17:16.737693Z","shell.execute_reply.started":"2025-01-10T19:17:11.370463Z","shell.execute_reply":"2025-01-10T19:17:16.736661Z"}},"outputs":[{"name":"stdout","text":"Name: torch\nVersion: 2.4.1+cu121\nSummary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\nHome-page: https://pytorch.org/\nAuthor: PyTorch Team\nAuthor-email: packages@pytorch.org\nLicense: BSD-3\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\nRequired-by: accelerate, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, timm, torchaudio, torchmetrics, torchvision\nName: torchvision\nVersion: 0.19.1+cu121\nSummary: image and video datasets and models for torch deep learning\nHome-page: https://github.com/pytorch/vision\nAuthor: PyTorch Core Team\nAuthor-email: soumith@pytorch.org\nLicense: BSD\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: numpy, pillow, torch\nRequired-by: easyocr, fastai, timm\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:17:16.738847Z","iopub.execute_input":"2025-01-10T19:17:16.739116Z","iopub.status.idle":"2025-01-10T19:17:21.692018Z","shell.execute_reply.started":"2025-01-10T19:17:16.739096Z","shell.execute_reply":"2025-01-10T19:17:21.691179Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# --- 1. Data Exploration ---\ndef explore_dataset(dataset_dir):\n    \"\"\"Explores the dataset, printing counts, dimensions, and pixel value info\"\"\"\n    for split in [\"test\", \"train\", \"val\"]:\n        for cls in [\"NORMAL\", \"PNEUMONIA\"]:\n            class_path = os.path.join(dataset_dir, split, cls)\n            images = os.listdir(class_path)\n            print(f\"  {split}/{cls}: {len(images)} images\")\n\n            if images:\n                img_path = os.path.join(class_path, images[0])\n                img = Image.open(img_path)\n                img_np = np.asarray(img)\n                print(f\"    Sample shape: {img_np.shape}\")\n                print(f\"    Sample min pixel value: {np.min(img_np)}\")\n                print(f\"    Sample max pixel value: {np.max(img_np)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:17:37.299410Z","iopub.execute_input":"2025-01-10T19:17:37.299693Z","iopub.status.idle":"2025-01-10T19:17:37.304811Z","shell.execute_reply.started":"2025-01-10T19:17:37.299673Z","shell.execute_reply":"2025-01-10T19:17:37.304034Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# --- 2. Data Preprocessing ---\ndef preprocess_dataset(dataset_dir, batch_size=32):\n    \"\"\"Preprocesses the dataset using torchvision and returns DataLoaders.\"\"\"\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),  # Converts to tensor and scales to [0,1]\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    train_dataset = datasets.ImageFolder(os.path.join(dataset_dir, \"train\"), transform=transform)\n    val_dataset = datasets.ImageFolder(os.path.join(dataset_dir, \"val\"), transform=transform)\n    test_dataset = datasets.ImageFolder(os.path.join(dataset_dir, \"test\"), transform=transform)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, val_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:17:52.349317Z","iopub.execute_input":"2025-01-10T19:17:52.349632Z","iopub.status.idle":"2025-01-10T19:17:52.354934Z","shell.execute_reply.started":"2025-01-10T19:17:52.349611Z","shell.execute_reply":"2025-01-10T19:17:52.354149Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# --- 3. Model Building (CNN) ---\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=2):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 56 * 56)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef create_model(learning_rate=0.001):\n    model = SimpleCNN()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    return model, optimizer, criterion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:18:29.527341Z","iopub.execute_input":"2025-01-10T19:18:29.527642Z","iopub.status.idle":"2025-01-10T19:18:29.533886Z","shell.execute_reply.started":"2025-01-10T19:18:29.527621Z","shell.execute_reply":"2025-01-10T19:18:29.532986Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# --- 4. Model Training ---\ndef train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device):\n    model.to(device)\n    start_time = time.time()\n\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        epoch_train_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            epoch_train_loss += loss.item()\n\n        avg_train_loss = epoch_train_loss/len(train_loader)\n        train_losses.append(avg_train_loss)\n        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\", end = \", \")\n\n        model.eval() #Eval mode to disable dropout, etc.\n        epoch_val_loss = 0.0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                epoch_val_loss += loss.item()\n\n        avg_val_loss = epoch_val_loss/len(val_loader)\n        val_losses.append(avg_val_loss)\n        print(f\"Val Loss: {avg_val_loss:.4f}\")\n    \n    elapsed = time.time() - start_time\n    print(f\"Training complete in {elapsed//60:.0f}m {elapsed%60:.0f}s\")\n    return model, train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:18:46.779352Z","iopub.execute_input":"2025-01-10T19:18:46.779638Z","iopub.status.idle":"2025-01-10T19:18:46.786264Z","shell.execute_reply.started":"2025-01-10T19:18:46.779617Z","shell.execute_reply":"2025-01-10T19:18:46.785266Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# --- 5. Model Evaluation ---\ndef evaluate_model(model, test_loader, device):\n    model.to(device)\n    model.eval() #Eval mode\n    all_labels = []\n    all_preds = []\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n\n    cm = confusion_matrix(all_labels, all_preds)\n    return accuracy, precision, recall, f1, cm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:19:01.734508Z","iopub.execute_input":"2025-01-10T19:19:01.734824Z","iopub.status.idle":"2025-01-10T19:19:01.740400Z","shell.execute_reply.started":"2025-01-10T19:19:01.734797Z","shell.execute_reply":"2025-01-10T19:19:01.739417Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# --- 6. Results Visualization ---\ndef visualize_results(cm, class_names, train_losses, val_losses, save_prefix):\n    \"\"\"Visualizes the confusion matrix and loss curves\"\"\"\n\n    # Confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted Labels\")\n    plt.ylabel(\"True Labels\")\n    plt.title(\"Confusion Matrix\")\n    plt.savefig(f\"{save_prefix}_cm.png\")\n    plt.close()\n\n    # Loss curves\n    plt.figure(figsize=(8,6))\n    plt.plot(train_losses, label=\"Training Loss\")\n    plt.plot(val_losses, label = \"Validation Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.title(\"Training and Validation Loss\")\n    plt.savefig(f\"{save_prefix}_loss.png\")\n    plt.close()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:19:15.921000Z","iopub.execute_input":"2025-01-10T19:19:15.921365Z","iopub.status.idle":"2025-01-10T19:19:15.926267Z","shell.execute_reply.started":"2025-01-10T19:19:15.921336Z","shell.execute_reply":"2025-01-10T19:19:15.925370Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# --- Main Execution ---\nif __name__ == '__main__':\n    base_dir = \"/kaggle/input/chest-xray-pneumonia\"  # Current directory\n    dataset_dir = os.path.join(base_dir, \"chest_xray\")\n    num_epochs = 10    # Set Number of training epochs\n    learning_rate = 0.001\n    save_prefix = \"cnn_results\"\n\n    # Check if CUDA is available, if not use the CPU.\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Device: {device}\")\n\n    # 1. Data Exploration\n    explore_dataset(dataset_dir)\n\n    # 2. Data Preprocessing\n    train_loader, val_loader, test_loader = preprocess_dataset(dataset_dir)\n    print(\"DataLoaders created\")\n\n    # 3. Model Building\n    model, optimizer, criterion = create_model(learning_rate)\n    print(\"Model created\")\n    print(model)\n    \n    # 4. Model Training\n    trained_model, train_losses, val_losses = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device)\n    print(\"Model training complete\")\n\n    # 5. Model Evaluation\n    accuracy, precision, recall, f1, cm = evaluate_model(trained_model, test_loader, device)\n    print(f\"\\nEvaluation Metrics:\")\n    print(f\"  Accuracy: {accuracy:.4f}\")\n    print(f\"  Precision: {precision:.4f}\")\n    print(f\"  Recall: {recall:.4f}\")\n    print(f\"  F1 Score: {f1:.4f}\")\n    \n    # 6. Results Visualization\n    class_names = [\"NORMAL\", \"PNEUMONIA\"]\n    visualize_results(cm, class_names, train_losses, val_losses, save_prefix)\n    print (f\"Results saved as {save_prefix}_cm.png and {save_prefix}_loss.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:20:37.582433Z","iopub.execute_input":"2025-01-10T19:20:37.582748Z","iopub.status.idle":"2025-01-10T19:36:37.730186Z","shell.execute_reply.started":"2025-01-10T19:20:37.582726Z","shell.execute_reply":"2025-01-10T19:36:37.729453Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n  test/NORMAL: 234 images\n    Sample shape: (941, 1612)\n    Sample min pixel value: 0\n    Sample max pixel value: 255\n  test/PNEUMONIA: 390 images\n    Sample shape: (1104, 1624)\n    Sample min pixel value: 0\n    Sample max pixel value: 255\n  train/NORMAL: 1341 images\n    Sample shape: (1128, 1336)\n    Sample min pixel value: 0\n    Sample max pixel value: 255\n  train/PNEUMONIA: 3875 images\n    Sample shape: (712, 1024)\n    Sample min pixel value: 0\n    Sample max pixel value: 255\n  val/NORMAL: 8 images\n    Sample shape: (1416, 1736)\n    Sample min pixel value: 0\n    Sample max pixel value: 255\n  val/PNEUMONIA: 8 images\n    Sample shape: (664, 1152)\n    Sample min pixel value: 0\n    Sample max pixel value: 255\nDataLoaders created\nModel created\nSimpleCNN(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=200704, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=2, bias=True)\n)\nEpoch 1/10, Train Loss: 0.4356, Val Loss: 0.8997\nEpoch 2/10, Train Loss: 0.1075, Val Loss: 1.1518\nEpoch 3/10, Train Loss: 0.0762, Val Loss: 2.0706\nEpoch 4/10, Train Loss: 0.0499, Val Loss: 0.8671\nEpoch 5/10, Train Loss: 0.0264, Val Loss: 0.8951\nEpoch 6/10, Train Loss: 0.0110, Val Loss: 1.7001\nEpoch 7/10, Train Loss: 0.0123, Val Loss: 1.0145\nEpoch 8/10, Train Loss: 0.0038, Val Loss: 1.3685\nEpoch 9/10, Train Loss: 0.0005, Val Loss: 1.5848\nEpoch 10/10, Train Loss: 0.0002, Val Loss: 1.6369\nTraining complete in 15m 43s\nModel training complete\n\nEvaluation Metrics:\n  Accuracy: 0.7788\n  Precision: 0.8218\n  Recall: 0.7788\n  F1 Score: 0.7528\nResults saved as cnn_results_cm.png and cnn_results_loss.png\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}